{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.sac.net.cn/tzgg/201910/P020191029644191573941.docx\n",
      "downloading: 111.4%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/tzgg/201909/P020190912550562035397.docx\n",
      "downloading: 100.9%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/tzgg/201908/P020190812592471226889.docx\n",
      "downloading: 107.4%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from http://so.kaipuyun.cn/view?qt=%E5%90%8D%E5%8D%95&location=41&reference=DEC87FFE7AAC834E10BEEA6F4C65E428&url=DF213102E43E854A890DFDEB67AF25E9EDFDD39CDFA1B5A64B5020A63A224462DF5A6A05FB050A02CF46FC1E299E80C54651F19400654248AC30B7B69C8D755C3821B3CE272D682BBF5B1B22D6A6F49AE803DEBADA1D0ADA29938030DAF371F6&title=%E9%99%84%E4%BB%B62%EF%BC%9A+%E9%9D%A2%E8%AF%95%E7%A1%AE%E8%AE%A4%E5%86%85%E5%AE%B9.docx&database=all&siteCode=bm35000001\n",
      "downloading: 752.9%\n",
      "Download finished!\n",
      "File size = 0.00 Mb\n",
      "Skipping this, need special attention for http://news.szhome.com/338103.html\n",
      "首批房产中介黑名单\n",
      "Skipping this, need special attention for https://3g.163.com/house/article/FHL73QCA00078224.html\n",
      "第二批批房产中介黑名单\n",
      "Skipping this, need special attention for https://m.credit100.com/xhxy/c/2020-07-21/624567.shtml?title=%E6%96%B0%E5%8D%8E%E4%BF%A1%E7%94%A8-%E4%BF%A1%E7%94%A8%E5%A4%B4%E6%9D%A1&from=groupmessage&isappinstalled=0\n",
      "首次发布环评信用平台失信黑名单\n",
      "Skipping this, need special attention for https://mp.weixin.qq.com/s/ODgW4cUU6QZvngW8VpIktQ\n",
      "全国人力资源诚信服务示范机构候选名单\n",
      "Skipping this, need special attention for https://mp.weixin.qq.com/s/qNsQmC4fN9S1mbsAA3OdiQ\n",
      "银行涉企违规收费名单\n",
      "Skipping this, need special attention for https://mp.weixin.qq.com/s/VMr3X1g_psMkcze_6Vlj6Q\n",
      "重大违法违规股东名单\n",
      "Skipping this, need special attention for https://mp.weixin.qq.com/s/lXA6wFetZsMzWPuWQ1JPvA\n",
      "非法从事场外配资平台名单\n",
      "Skipping this, need special attention for https://www.msa.gov.cn/page/article.do?articleId=423B298D-156B-42FB-A02C-B73E9DD349A9\n",
      "2019年度安全诚信航运公司候选名单\n",
      "Skipping this, need special attention for http://www.mohrss.gov.cn/SYrlzyhshbzb/dongtaixinwen/buneiyaowen/202007/t20200730_381374.html\n",
      "拖欠农民工工资“黑名单”\n",
      "Downloading data from https://www.sac.net.cn/tzgg/202007/P020200731360184604641.docx\n",
      "downloading: 114.0%\n",
      "Download finished!\n",
      "File size = 0.03 Mb\n",
      "Downloading data from http://www.csrc.gov.cn/pub/hainan/xxfw/hnsmjzzjy/202005/P020200509557176227431.docx\n",
      "downloading: 108.8%\n",
      "Download finished!\n",
      "File size = 0.05 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/hmd/202003/P020200319597291643986.docx\n",
      "downloading: 103.6%\n",
      "Download finished!\n",
      "File size = 0.05 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/hmd/202002/P020200227493399588656.docx\n",
      "downloading: 121.6%\n",
      "Download finished!\n",
      "File size = 0.03 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/hmd/202001/P020200117633729068352.docx\n",
      "downloading: 106.7%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/zfjl/201912/P020191230584118724669.docx\n",
      "downloading: 108.3%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/zfjl/201910/P020191029645936216142.docx\n",
      "downloading: 111.4%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/hmd/201909/P020190912552754728874.docx\n",
      "downloading: 100.9%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/hmd/201908/P020190812592872204293.docx\n",
      "downloading: 107.4%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/zfjl/201907/P020190712595118571092.docx\n",
      "downloading: 104.3%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/zfjl/201906/P020190619526102152491.docx\n",
      "downloading: 106.4%\n",
      "Download finished!\n",
      "File size = 0.04 Mb\n",
      "Downloading data from https://www.sac.net.cn/wlzf/zfjl/201905/P020190507608302538668.docx\n",
      "Skipping this, need special attention for https://www.sac.net.cn/wlzf/zfjl/201905/t20190507_138578.html\n",
      "非法仿冒券商和投资咨询机构黑名单\n",
      "Skipping this, need special attention for https://www.sac.net.cn/wlzf/zfjl/201904/t20190404_138302.html\n",
      "非法仿冒券商和投资咨询机构黑名单\n",
      "Skipping this, need special attention for http://www.csrc.gov.cn/guangxi/xxfw/tjyg/201810/t20181017_345402.htm\n",
      "非法仿冒券商和投资咨询机构黑名单\n",
      "Skipping this, need special attention for http://zjt.aniu.tv/Index_detail_wzid_107891.shtml\n",
      "非法仿冒券商和投资咨询机构黑名单\n",
      "Skipping this, need special attention for http://www.mohrss.gov.cn/ldjcj/LDJCJgongzuodongtai/202005/t20200512_368309.html\n",
      "拖欠农民工工资“黑名单”\n",
      "Skipping this, need special attention for http://www.mohrss.gov.cn/ldjcj/LDJCJgongzuodongtai/202001/t20200108_352996.html\n",
      "拖欠农民工工资“黑名单”\n",
      "Skipping this, need special attention for http://www.mohrss.gov.cn/ldjcj/LDJCJgongzuodongtai/201907/t20190719_325048.html\n",
      "拖欠农民工工资“黑名单”\n",
      "Skipping this, need special attention for http://www.mohrss.gov.cn/ldjcj/LDJCJgongzuodongtai/201907/t20190719_325162.html\n",
      "拖欠农民工工资“黑名单”\n",
      "Skipping this, need special attention for http://www.mohrss.gov.cn/ldjcj/LDJCJgongzuodongtai/201903/t20190321_312696.html\n",
      "拖欠农民工工资“黑名单”\n",
      "Skipping this, need special attention for http://zwgk.mct.gov.cn/auto255/201911/t20191128_849173.html?keywords=\n",
      "全国旅游市场黑名单\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "from selenium import webdriver\n",
    "import socket\n",
    "import time\n",
    "import ssl\n",
    "df = pd.read_csv(\"excel_urls.csv\",header=None,delimiter=\"\\t\")\n",
    "\n",
    "def get_driver_url_content(url, encoding='utf-8', timeout=3):\n",
    "    '''\n",
    "    使用浏览器获取动态内容\n",
    "    :param url:         网页url\n",
    "    :param encoding:    网页编码\n",
    "    :param timeout:     设置超时\n",
    "    :return:\n",
    "    '''\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    # 也可以使用phantomJS\n",
    "    # driver =webdriver.Phantomjs(executable_path=\"/path/to/phantomjs\")\n",
    "    driver.get(url)\n",
    "    time.sleep(timeout)\n",
    "    try:\n",
    "        files = driver.find_elements_by_xpath(\"//*[contains(text(), 'docx')]\")\n",
    "        for i in files:\n",
    "            if i.text!=\"\":\n",
    "                file = i\n",
    "    \n",
    "        href = file.get_attribute(\"href\")\n",
    "        driver.close()\n",
    "        \n",
    "    except:\n",
    "        driver.close()\n",
    "    return href    \n",
    "\n",
    "\n",
    "\n",
    "def download(url,name,savepath='./'):\n",
    "    \"\"\"\n",
    "    download file from internet\n",
    "    :param url: path to download from\n",
    "    :param savepath: path to save files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    def reporthook(a, b, c):\n",
    "        \"\"\"\n",
    "        显示下载进度\n",
    "        :param a: 已经下载的数据块\n",
    "        :param b: 数据块的大小\n",
    "        :param c: 远程文件大小\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        print(\"\\rdownloading: %5.1f%%\" % (a * b * 100.0 / c), end=\"\")\n",
    "    # 判断文件是否存在，如果不存在则下载\n",
    "    filename = name+\".docx\"\n",
    "    if not os.path.isfile(os.path.join(savepath, filename)):\n",
    "        print('Downloading data from %s' % url)\n",
    "        urlretrieve(url, os.path.join(savepath, filename), reporthook=reporthook)\n",
    "        print('\\nDownload finished!')\n",
    "    else:\n",
    "        print('File already exsits!')\n",
    "    # 获取文件大小\n",
    "    filesize = os.path.getsize(os.path.join(savepath, filename))\n",
    "    # 文件大小默认以Bytes计， 转换为Mb\n",
    "    print('File size = %.2f Mb' % (filesize/1024/1024))\n",
    "if __name__ == '__main__':\n",
    "    # 以下载cifar-10数据集为例\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    urls = df[4].values\n",
    "    names = df[0].values\n",
    "    for i in range(len(urls)):\n",
    "        url = urls[i]\n",
    "        filename = str(i)\n",
    "        try:\n",
    "            a = get_driver_url_content(url)\n",
    "            download(a,filename,savepath='./docx/')\n",
    "        except:\n",
    "            print(\"Skipping this, need special attention for \"+url)\n",
    "            print(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP \n",
    "import cx_Oracle as oracle\n",
    "import pandas as pd\n",
    "import re\n",
    "#print(len(doc.tables[0].rows))\n",
    "def doc_to_df(doc):\n",
    "    pattern2 = re.compile(r\"博客\")\n",
    "    pattern = re.compile(r\"类别|表现形式|[1-9]+|序号\")\n",
    "    row_nums = []\n",
    "    row_type = []\n",
    "    tb = doc.tables[0]\n",
    "    for row_num in range(len(tb.rows)):\n",
    "        row_title = tb.rows[row_num].cells[0].text\n",
    "        if bool(pattern.search(row_title))==False:\n",
    "            row_nums.append(row_num+1)\n",
    "            row_type.append(row_title)\n",
    "    \n",
    "    row_nums.append(len(tb.rows))\n",
    "    for i in range(len(row_nums)-1):\n",
    "        find_df(tb,row_nums[i],row_nums[i+1]-1)\n",
    "\n",
    "def data_output(data,dataTable):\n",
    "    connection = db\n",
    "    cursor = connection.cursor()\n",
    "    query = \"INSERT INTO \"+ dataTable + \" VALUES ({})\"\n",
    "    columns = list(data.columns)\n",
    "    aidx = list(range(1,len(columns)+1))\n",
    "    aidx = [':'+str(i) for i in aidx]\n",
    "    aname = ','.join(aidx)\n",
    "    dtHigh = data.shape[0]\n",
    "    dtWidth = data.shape[1]\n",
    "    creatVar = locals()\n",
    "    wholeData = []\n",
    "    for i in range(dtHigh):\n",
    "        value_list = []\n",
    "        for j in range(dtWidth):\n",
    "            value_list.append(\"{}\".format(str(data.iloc[i,j])))\n",
    "        wholeData.append(value_list)\n",
    "    cursor.executemany(query.format(aname),wholeData)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    return\n",
    "import numpy as np\n",
    "def find_df(tb,row1,row2):\n",
    "    index,bad_urls,bad_type,date,descriptions=[],[],[],[],[]\n",
    "    table_index=0\n",
    "    pattern = re.compile(r\"(http.+|www.+)\")\n",
    "    pattern2 = re.compile(r\"(.+)http:/.+\")\n",
    "    pattern3 = re.compile(r\"\\“(.+)”\")\n",
    "    pattern4 = re.compile(r\"\\：(.+)http\")\n",
    "    \n",
    "    for row in tb.rows[row1:row2]:\n",
    "        text= \"\"\n",
    "        for p in row.cells[2].paragraphs:##如果cell中有多段，即有回车符\n",
    "            text+=p.text\n",
    "        try:\n",
    "            url = re.findall(pattern,text)[0]\n",
    "        except:\n",
    "            url = None\n",
    "\n",
    "        if url == None:\n",
    "            continue\n",
    "        bad_type.append(row.cells[3].text)         \n",
    "        bad_urls.append(url)\n",
    "        descriptions.append(row.cells[1].text)\n",
    "        date.append(row.cells[4].text)\n",
    "        index.append(row.cells[0].text)#这行也可以放在else中\n",
    "\n",
    "    df=pd.DataFrame({\"index\":index,'date':date,\"bad_url\":bad_urls,\"bad_type\":bad_type,\"description\":descriptions})\n",
    "    df = df.replace(dict_type)\n",
    "    data_output(df,\"bad_website\")\n",
    "\n",
    "def get_stock_df(doc):\n",
    "    \n",
    "    tb = doc.tables[0]\n",
    "    index,stock_num,iname,start,end = [],[],[],[],[]\n",
    "    for row in tb.rows[1:]:\n",
    "        \n",
    "        cells = row.cells\n",
    "        index.append(cells[0].text)\n",
    "        stock_num.append(cells[1].text)\n",
    "        iname.append(cells[2].text)\n",
    "        start.append(cells[3].text.replace(\"年\",\"-\").replace(\"月\",\"-\").replace(\"日\",\"-\"))\n",
    "        end.append(cells[4].text.replace(\"年\",\"-\").replace(\"月\",\"-\").replace(\"日\",\"-\"))\n",
    "    df = pd.DataFrame({\"row_index\":index,\"stock_name\":stock_num,\"iname\":iname,\"start_date\":start,\"end_date\":end})\n",
    "    data_output(df,\"stock_peishou\")\n",
    "    return df\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    username = input(\"Username(必须大写）:   \")\n",
    "    password = input(\"Password:   \")\n",
    "    database_ip = input(\"数据库IP(默认127.0.0.1):   \")\n",
    "    port = input(\"Port(默认1521):    \")\n",
    "    database = input(\"服务名/数据库(默认orcl):    \")\n",
    "    string = username+\"/\"+password+\"@\"+database_ip+\":\"+\"port\"+\"/\"+database\n",
    "    try:\n",
    "        db = oracle.connet(string)\n",
    "    except:\n",
    "        db = oracle.connect('tenant01/123456@127.0.0.1:1521/orcl')\n",
    "    dict_df = pd.read_csv(\"type_dict.csv\")\n",
    "    dict_type = dict(zip(dict_df[\"type\"],dict_df[\"description\"]))\n",
    "    a = [0,1,2]+list(range(14,26))\n",
    "\n",
    "    for i in a:\n",
    "        file = str(i)+\".docx\"\n",
    "        doc_path = os.path.join(os.getcwd(), \"docx\\\\\"+file)\n",
    "        print(doc_path)\n",
    "        document = docx.Document(doc_path)\n",
    "        doc_to_df(document)\n",
    "    doc_path = os.path.join(os.getcwd(), \"docx\\\\\"+\"13.docx\")\n",
    "    doc = docx.Document(doc_path)\n",
    "    get_stock_df(doc)\n",
    "    db.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其中 0，1，2，14-25 是同一类数据，13是一类数据（含有表格的docx文件），其他的都需要特殊处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
